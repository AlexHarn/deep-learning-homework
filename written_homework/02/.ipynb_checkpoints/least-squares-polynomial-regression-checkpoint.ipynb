{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p126BTGtzmCa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buZzB1dMzmCh"
   },
   "outputs": [],
   "source": [
    "def target_fun(x):\n",
    "    return np.sin(x*10)\n",
    "\n",
    "def gen_data(n,d, domain):\n",
    "    X = np.random.uniform(domain[0], domain[1], size = n)\n",
    "    t = target_fun(X) + np.random.normal(size=X.shape)*0.1\n",
    "    return X, t\n",
    "\n",
    "def poly_expand(X, d=20, poly_type = 'legendre'):\n",
    "  if poly_type == 'legendre':\n",
    "    return np.polynomial.legendre.legvander(X, d)\n",
    "  if poly_type == 'chebyshev':\n",
    "    return np.polynomial.chebyshev.chebvander(X, d)\n",
    "  if poly_type == 'bspline':\n",
    "    out = np.zeros((len(X), d))\n",
    "    for i in range(d):\n",
    "        out[:,i] = sps.bspline(X - (i+1)/2, i)[:]\n",
    "    return out\n",
    "\n",
    "def plot_prediction(X, W, t, d, domain, plot=True):\n",
    "  X_expand = poly_expand(X, d=d, poly_type = poly_type)\n",
    "  p_train = X_expand.dot(W)\n",
    "  loss = (((t - p_train)**2)*0.5).mean()\n",
    "\n",
    "  X_val_raw = np.linspace(domain[0], domain[1], 1000)\n",
    "  X_val_expand = poly_expand(X_val_raw, d=d, poly_type = poly_type)\n",
    "  p_val = X_val_expand.dot(W)\n",
    "  t_val = target_fun(X_val_raw)\n",
    "  loss_val = (((t_val - p_val)**2)*0.5).mean()\n",
    "  \n",
    "  if plot:\n",
    "    plt.plot(X_val_raw, p_val, label='deg {}'.format(d))\n",
    "    plt.plot(X, t, 'o')\n",
    "    plt.plot(X, p_train, '*')\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.xlim(domain[0], domain[1])\n",
    "  return loss_val\n",
    "\n",
    "def plot_target_func():\n",
    "  x = np.linspace(0, 1, 1000)\n",
    "  plt.plot(x, target_fun(x), '--', label=\"target func\")\n",
    "\n",
    "def plot_val_loss(poly_degrees, losses):\n",
    "  plt.figure()\n",
    "  plt.plot(poly_degrees, losses)\n",
    "  plt.semilogy()\n",
    "  plt.semilogx()\n",
    "  plt.ylim(1e-2, 1e2)\n",
    "  plt.ylabel('test loss')\n",
    "  plt.xlabel('poly degrees')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xK2GJsstfL3K"
   },
   "outputs": [],
   "source": [
    "# to be implemented; fill in the derived solution for the underparameterized (d<n) and overparameterized (d>n) problem\n",
    "\n",
    "def fit_poly(X, d, t):\n",
    "  X_expand = poly_expand(X, d=d, poly_type = poly_type)\n",
    "  if d > n:\n",
    "        # W = ... fill your answer here\n",
    "  else:\n",
    "        # W = ... fill your answer here\n",
    "  return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Zc3Ll1J5fC92",
    "outputId": "bb7871d3-2867-4c07-b542-5eb91c6ec2c2"
   },
   "outputs": [],
   "source": [
    "domain = [0., 1.]\n",
    "n = 15\n",
    "np.random.seed(123)\n",
    "X, t = gen_data(n, 1, domain)\n",
    "\n",
    "plt.plot(X, t, 'o')\n",
    "plot_target_func()\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(domain[0], domain[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "wH2w0ftCfJ4y",
    "outputId": "ce0392dc-c7b0-452b-c6f2-e1c321d09222"
   },
   "outputs": [],
   "source": [
    "poly_type = 'bspline' # try legendre or chebyshev or bspline\n",
    "loss_val_list = []\n",
    "\n",
    "poly_degrees = [2, 3, 4, 5, 7, 10, 15, 20,30,50,70,100,150,200] \n",
    "plot_poly_degress = [4, 7, 10, 70, 150] ## only plot these polynomials\n",
    "##  \n",
    "plot_target_func()\n",
    "\n",
    "for d in poly_degrees:\n",
    "  W = fit_poly(X, d, t)\n",
    "  plot_flag = True if d in plot_poly_degress else False\n",
    "  loss_val = plot_prediction(X, W, t, d, domain, plot_flag)\n",
    "  loss_val_list.append(loss_val)\n",
    "plt.legend()\n",
    "\n",
    "plot_val_loss(poly_degrees, loss_val_list)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_polynomial_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
